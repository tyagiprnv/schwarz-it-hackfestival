# -*- coding: utf-8 -*-
"""Untitled37.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wl6Uc-uOZ1QEm9rLEbBd4EbUE0g5GPYK
"""

!pip install langchain langchain_community langchain_chroma faiss-cpu sentence-transformers transformers

!export CUDA_LAUNCH_BLOCKING=1

import pandas as pd

from langchain.vectorstores import FAISS
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.document_loaders import TextLoader
from langchain.prompts import PromptTemplate
from langchain.llms import HuggingFacePipeline
from langchain.chains import LLMChain
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline

model_name = "meta-llama/Llama-2-7b-hf"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(model_name)
generator = pipeline("text-generation", model=model, tokenizer=tokenizer, max_new_tokens=100)

llm = HuggingFacePipeline(pipeline=generator)

inventory_loader = TextLoader("inventory.txt")
embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
inventory_docs = inventory_loader.load()
inventory_store = FAISS.from_documents(inventory_docs, embedding_model)
inventory_retriever = inventory_store.as_retriever()

prompt_template = """
Based on the user's purchase history:
{purchase_history}

And the available inventory items:
{inventory}

Please recommend relevant items that the user might want to purchase next.
"""

prompt = PromptTemplate(
    input_variables=["purchase_history", "inventory"],
    template=prompt_template
)

llm_chain = LLMChain(llm=llm, prompt=prompt)


purchase_data = pd.read_csv("hist.csv")

def fetch_purchase_history(c_name):
    user_data = purchase_data[purchase_data['company_name'] == c_name]

    purchase_history_text = ", ".join(user_data['item'].tolist())
    return purchase_history_text


def recommend_items(c_name):
    purchase_history_text = fetch_purchase_history(c_name)

    # Retrieve relevant inventory documents based on user's purchase history
    inventory_result = inventory_retriever.get_relevant_documents(purchase_history_text)
    inventory_text = "\n".join([doc.page_content for doc in inventory_result])

    # Run the LLM chain to generate recommendations
    recommendations = llm_chain.run({
        "purchase_history": purchase_history_text,
        "inventory": inventory_text
    })

    return recommendations



c_name = "Company_1"
recommendations = recommend_items(c_name)
print(recommendations)

